<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"lingmoumou.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="任务理论部分 相关概念 无监督学习 聚类的定义   常用距离公式 曼哈顿距离 欧式距离 闵可夫斯基距离 切比雪夫距离 夹角余弦 汉明距离 杰卡德相似系数 杰卡德距离   K-Means聚类：聚类过程和原理、算法流程、算法优化（k-means++、Mini Batch K-Means） 层次聚类：Agglomerative Clustering过程和原理 密度聚类：DBSCAN过程和原理 谱聚类：谱">
<meta name="keywords" content="datawhale,ml,机器学习,machine learning,cluster,聚类">
<meta property="og:type" content="article">
<meta property="og:title" content="Day5 聚类">
<meta property="og:url" content="https://lingmoumou.github.io/p/2020/01/19/c40f9711/index.html">
<meta property="og:site_name" content="Lingmoumou&#39;s Blog">
<meta property="og:description" content="任务理论部分 相关概念 无监督学习 聚类的定义   常用距离公式 曼哈顿距离 欧式距离 闵可夫斯基距离 切比雪夫距离 夹角余弦 汉明距离 杰卡德相似系数 杰卡德距离   K-Means聚类：聚类过程和原理、算法流程、算法优化（k-means++、Mini Batch K-Means） 层次聚类：Agglomerative Clustering过程和原理 密度聚类：DBSCAN过程和原理 谱聚类：谱">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2021-01-31T13:53:26.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Day5 聚类">
<meta name="twitter:description" content="任务理论部分 相关概念 无监督学习 聚类的定义   常用距离公式 曼哈顿距离 欧式距离 闵可夫斯基距离 切比雪夫距离 夹角余弦 汉明距离 杰卡德相似系数 杰卡德距离   K-Means聚类：聚类过程和原理、算法流程、算法优化（k-means++、Mini Batch K-Means） 层次聚类：Agglomerative Clustering过程和原理 密度聚类：DBSCAN过程和原理 谱聚类：谱">

<link rel="canonical" href="https://lingmoumou.github.io/p/2020/01/19/c40f9711/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Day5 聚类 | Lingmoumou's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lingmoumou's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">きっといつかって愿うまま</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lingmoumou.github.io/p/2020/01/19/c40f9711/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Ling Moumou">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lingmoumou's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Day5 聚类
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-01-19 20:48:19" itemprop="dateCreated datePublished" datetime="2020-01-19T20:48:19+08:00">2020-01-19</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-01-31 21:53:26" itemprop="dateModified" datetime="2021-01-31T21:53:26+08:00">2021-01-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Datawhale/" itemprop="url" rel="index"><span itemprop="name">Datawhale</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Datawhale/初级算法梳理/" itemprop="url" rel="index"><span itemprop="name">初级算法梳理</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h2><h3 id="理论部分"><a href="#理论部分" class="headerlink" title="理论部分"></a>理论部分</h3><ul>
<li>相关概念<ul>
<li>无监督学习</li>
<li>聚类的定义</li>
</ul>
</li>
<li>常用距离公式<ul>
<li>曼哈顿距离</li>
<li>欧式距离</li>
<li>闵可夫斯基距离</li>
<li>切比雪夫距离</li>
<li>夹角余弦</li>
<li>汉明距离</li>
<li>杰卡德相似系数</li>
<li>杰卡德距离</li>
</ul>
</li>
<li>K-Means聚类：聚类过程和原理、算法流程、算法优化（k-means++、Mini Batch K-Means）</li>
<li>层次聚类：Agglomerative Clustering过程和原理</li>
<li>密度聚类：DBSCAN过程和原理</li>
<li>谱聚类：谱聚类原理（邻接矩阵、度矩阵、拉普拉斯矩阵、RatioCut、Ncut）和过程</li>
<li>高斯混合聚类：GMM过程和原理、EM算法原理、利用EM算法估计高斯混合聚类参数</li>
<li>sklearn参数详解</li>
</ul>
<h3 id="练习部分"><a href="#练习部分" class="headerlink" title="练习部分"></a>练习部分</h3><p><a href="https://github.com/datawhalechina/team-learning/blob/master/初级算法梳理/Task5_cluster_plus.ipynb" target="_blank" rel="noopener">https://github.com/datawhalechina/team-learning/blob/master/初级算法梳理/Task5_cluster_plus.ipynb</a></p>
<ul>
<li>利用sklearn解决聚类问题。</li>
<li>sklearn.cluster.KMeans</li>
</ul>
<a id="more"></a>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><ul>
<li><strong>无监督学习</strong>： 无监督学习是机器学习的一种方法，没有给定事先标记过的训练示例，自动对输入的数据进行分类或分群。无监督学习的主要运用包含：聚类分析、关系规则、维度缩减。它是监督式学习和强化学习等策略之外的一种选择。 一个常见的无监督学习是数据聚类。在人工神经网络中，生成对抗网络、自组织映射和适应性共振理论则是最常用的非监督式学习。</li>
<li><strong>聚类</strong>： 聚类是一种无监督学习。聚类是把相似的对象通过静态分类的方法分成不同的组别或者更多的子集，这样让在同一个子集中的成员对象都有相似的一些属性，常见的包括在坐标系中更加短的空间距离等。</li>
</ul>
<p>通过简单的例子来直接查看K均值聚类的效果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类前</span></span><br><span class="line">X = np.random.rand(<span class="number">100</span>, <span class="number">2</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], marker=<span class="string">'o'</span>)</span><br><span class="line">plt.show() <span class="comment">#pic1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类后</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">2</span>).fit(X)</span><br><span class="line">label_pred = kmeans.labels_</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=label_pred)</span><br><span class="line">plt.show() <span class="comment">#pic2</span></span><br></pre></td></tr></table></figure></p>
<p><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/sogo20200119214622.png" alt="pic1"></p>
<p><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/sogo20200119214642.png" alt="pic2"></p>
<h3 id="性能度量-4"><a href="#性能度量-4" class="headerlink" title="性能度量 ^4"></a>性能度量 <a href="https://www.zybuluo.com/rianusr/note/1199877" target="_blank" rel="noopener">^4</a></h3><p>在机器学习中我们都需要对任务进行评价以便于进行下一步的优化，聚类的性能度量主要有一下两种。</p>
<ul>
<li>外部指标：是指把算法得到的划分结果跟某个外部的“参考模型”（如专家给出的划分结果）比较</li>
<li>内部指标：是指直接考察聚类结果，不利用任何参考模型的指标。</li>
</ul>
<h3 id="距离计算"><a href="#距离计算" class="headerlink" title="距离计算"></a>距离计算</h3><p>在机器学习和数据挖掘中，我们经常需要知道个体间差异的大小，进而评价个体的相似性和类别。</p>
<h4 id="欧式距离"><a href="#欧式距离" class="headerlink" title="欧式距离"></a>欧式距离</h4><p>欧氏距离是最易于理解的一种距离计算方法，源自欧氏空间中两点间的距离公式。<br>$$d(x,y)=\sqrt{\Sigma_{k=1}^n (x_k-y_k)^2}$$</p>
<h4 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h4><p>曼哈顿距离也称为街区距离，计算公式如下：<br>$$d(x,y)=\Sigma_{k=1}^n \left|x_k-y_k\right|$$</p>
<h4 id="切比雪夫距离"><a href="#切比雪夫距离" class="headerlink" title="切比雪夫距离"></a>切比雪夫距离</h4><p>$$d(x,y) = \lim_{n\rightarrow \infty} (\Sigma_{k=1}^n (\left|x_k-y_k\right|)^r)^\dfrac{1}{r} = max_k (\left|x_k-y_k\right|)$$</p>
<h4 id="闵可夫斯基距离"><a href="#闵可夫斯基距离" class="headerlink" title="闵可夫斯基距离"></a>闵可夫斯基距离</h4><p>$$d(x,y)=(\Sigma_{k=1}^n (\left|x_k-y_k\right|)^r)^\dfrac{1}{r}$$<br>式中，r是一个可变参数，根据参数r取值的不同，闵可夫斯基距离可以表示一类距离</p>
<ul>
<li>r = 1时，为曼哈顿距离</li>
<li>r = 2时，为欧式距离</li>
<li>r →∞时，为切比雪夫距离</li>
</ul>
<p>闵可夫斯基距离包括欧式距离、曼哈顿距离、切比雪夫距离都假设数据各维属性的量纲和分布（期望、方差）相同，因此适用于度量独立同分布的数据对象。</p>
<h4 id="余弦距离"><a href="#余弦距离" class="headerlink" title="余弦距离"></a>余弦距离</h4><p>余弦相似度公式定义如下：<br>$$cos⁡(x,y)=\dfrac{xy}{\left|x\right|\left|y\right|} = \dfrac{\Sigma_{k=1}^n x_k y_k}{\sqrt{\Sigma_{k=1}^n x_k^2} \sqrt{\Sigma_{k=1}^n y_k^2}}$$<br>余弦相似度实际上是向量xx和yy夹角的余弦度量，可用来衡量两个向量方向的差异。如果余弦相似度为11，则xx和yy之间夹角为0°0°，两向量除模外可认为是相同的；如果预先相似度为00，则xx和yy之间夹角为90°90°，则认为两向量完全不同。在计算余弦距离时，将向量均规范化成具有长度11，因此不用考虑两个数据对象的量值。 余弦相似度常用来度量文本之间的相似性。文档可以用向量表示，向量的每个属性代表一个特定的词或术语在文档中出现的频率，尽管文档具有大量的属性，但每个文档向量都是稀疏的，具有相对较少的非零属性值。<br><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/image_1chf96u471s12en1lji15vb1gvo9.png" alt="余弦距离"></p>
<h4 id="马氏距离"><a href="#马氏距离" class="headerlink" title="马氏距离"></a>马氏距离</h4><p>$$mahalanobis(x,y)=(x-y)\Sigma^{-1}(x-y)^T$$<br>式中，Σ−1Σ−1是数据协方差矩阵的逆。 前面的距离度量方法大都假设样本独立同分布、数据属性之间不相关。马氏距离考虑了数据属性之间的相关性，排除了属性间相关性的干扰，而且与量纲无关。若协方差矩阵是对角阵，则马氏距离变成了标准欧式距离；若协方差矩阵是单位矩阵，各个样本向量之间独立同分布，则变成欧式距离。<br><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/image_1chd8cv6quhfu13kl7jme13df29.png" alt="马氏距离"></p>
<h3 id="原型聚类"><a href="#原型聚类" class="headerlink" title="原型聚类"></a>原型聚类</h3><p>原型聚类亦称”基于原型的聚类” (prototype-based clustering)，此类算法假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用.通常情形下，算法先对原型进行初始化，然后对原型进行迭代更新求解.采用不同的原型表示、不同的求解方式，将产生不同的算法.</p>
<h4 id="K均值"><a href="#K均值" class="headerlink" title="K均值"></a>K均值</h4><p><strong>k均值聚类算法（k-means clustering algorithm）</strong>是一种迭代求解的聚类分析算法，其步骤是</p>
<blockquote>
<p>1: 创建 k 个点作为起始质心（通常是随机选择）<br>2: 当任意一个点的簇分配结果发生改变时（不改变时算法结束）<br>3: 　　对数据集中的每个数据点<br>4: 　　　　对每个质心<br>5: 　　　　　　计算质心与数据点之间的距离<br>6: 　　　　将数据点分配到距其最近的簇<br>7: 　　对每一个簇, 计算簇中所有点的均值并将均值作为质心<br>8: 聚类中心以及分配给它们的对象就代表一个聚类。</p>
</blockquote>
<p><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/v2-77e1b4e663ba45f0ced9839149e06b0d_r.jpg" alt="K均值算法"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA, vecB)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    欧氏距离计算函数</span></span><br><span class="line"><span class="string">    :param vecA:</span></span><br><span class="line"><span class="string">    :param vecB:</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    :return: float </span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    dist = <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    dist = np.sqrt(np.sum(np.square(vecA - vecB)))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataMat, k)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    为给定数据集构建一个包含K个随机质心的集合,</span></span><br><span class="line"><span class="string">    随机质心必须要在整个数据集的边界之内,这可以通过找到数据集每一维的最小和最大值来完成</span></span><br><span class="line"><span class="string">    然后生成0到1.0之间的随机数并通过取值范围和最小值,以便确保随机点在数据的边界之内</span></span><br><span class="line"><span class="string">    :param np.dataMat:</span></span><br><span class="line"><span class="string">    :param k:</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    :return: np.dataMat</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 获取样本数与特征值</span></span><br><span class="line">    m, n = np.shape(dataMat)</span><br><span class="line">    <span class="comment"># 初始化质心,创建(k,n)个以零填充的矩阵</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    print(centroids)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 循环遍历特征值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        min_J= np.min(dataMat[:,i])</span><br><span class="line">        range_J = float(np.max(dataMat[:,i])-min_J)</span><br><span class="line">        </span><br><span class="line">        centroids[:,i] = np.mat(min_J+range_J * np.random.rand(k,<span class="number">1</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回质心</span></span><br><span class="line">    <span class="keyword">return</span> centroids.A</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataMat, k, distMeas=distEclud)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    创建K个质心,然后将每个店分配到最近的质心,再重新计算质心。</span></span><br><span class="line"><span class="string">    这个过程重复数次,直到数据点的簇分配结果不再改变为止</span></span><br><span class="line"><span class="string">    :param dataMat: 数据集</span></span><br><span class="line"><span class="string">    :param k: 簇的数目</span></span><br><span class="line"><span class="string">    :param distMeans: 计算距离</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment"># 获取样本数和特征数</span></span><br><span class="line">    m, n = np.shape(dataMat)</span><br><span class="line">    <span class="comment"># 初始化一个矩阵来存储每个点的簇分配结果</span></span><br><span class="line">    <span class="comment"># clusterAssment包含两个列:一列记录簇索引值,第二列存储误差(误差是指当前点到簇质心的距离,后面会使用该误差来评价聚类的效果)</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    <span class="comment"># 创建质心,随机K个质心</span></span><br><span class="line">    centroids = randCent(dataMat, k)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化标志变量,用于判断迭代是否继续,如果True,则继续迭代</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 遍历所有数据找到距离每个点最近的质心,</span></span><br><span class="line">        <span class="comment"># 可以通过对每个点遍历所有质心并计算点到每个质心的距离来完成</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            minDist = float(<span class="string">"inf"</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span><br><span class="line">                <span class="comment"># 计算数据点到质心的距离</span></span><br><span class="line">                <span class="comment"># 计算距离是使用distMeas参数给出的距离公式,默认距离函数是distEclud</span></span><br><span class="line">                distJI = distMeas(centroids[j, :], dataMat[i, :])</span><br><span class="line">                <span class="comment"># 如果距离比minDist(最小距离)还小,更新minDist(最小距离)和最小质心的index(索引)</span></span><br><span class="line">                <span class="keyword">if</span> distJI &lt; minDist:</span><br><span class="line">                    minDist = distJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果任一点的簇分配结果发生改变,则更新clusterChanged标志</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex: </span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 更新簇分配结果为最小质心的index(索引),minDist(最小距离)的平方</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist ** <span class="number">2</span></span><br><span class="line">        <span class="comment"># print(centroids)</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 遍历所有质心并更新它们的取值</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">            <span class="comment">#取每个质心周围所有的点</span></span><br><span class="line">            point = dataMat[np.nonzero(clusterAssment[:,<span class="number">0</span>].A==i)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment"># 计算所有点的均值,axis=0表示沿矩阵的列方向进行均值计算</span></span><br><span class="line">            centroids[i,:] = np.mean(point,axis=<span class="number">0</span>)</span><br><span class="line">                </span><br><span class="line">    <span class="comment"># 返回所有的类质心与点分配结果</span></span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行Kmeans，假设有两聚类中心</span></span><br><span class="line">center,label_pred = kMeans(X, k=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将标签转化成易绘图的形式</span></span><br><span class="line">label = label_pred[:, <span class="number">0</span>].A.reshape(<span class="number">-1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将结果可视化</span></span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=label)</span><br><span class="line">plt.scatter(center[<span class="number">0</span>, <span class="number">0</span>], center[<span class="number">0</span>, <span class="number">1</span>], marker=<span class="string">"*"</span>, s = <span class="number">100</span>)</span><br><span class="line">plt.scatter(center[<span class="number">1</span>, <span class="number">0</span>], center[<span class="number">1</span>, <span class="number">1</span>], marker=<span class="string">"*"</span>, s = <span class="number">100</span>)</span><br><span class="line">plt.show() <span class="comment"># pic3</span></span><br></pre></td></tr></table></figure>
<p><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/sogo20200119215336.png" alt="pic3"></p>
<h4 id="LVQ-7"><a href="#LVQ-7" class="headerlink" title="LVQ ^7"></a>LVQ <a href="http://ddrv.cn/a/66611" target="_blank" rel="noopener">^7</a></h4><p><strong>学习向量量化(Learning Vector Quantization,简称LVQ)</strong>属于原型聚类，即试图找到一组原型向量来聚类，每个原型向量代表一个簇，将空间划分为若干个簇，从而对于任意的样本，可以将它划入到它距离最近的簇中，不同的是LVQ假设数据样本带有类别标记，因此可以利用这些类别标记来辅助聚类。</p>
<p>大致思想如下：</p>
<ol>
<li>统计样本的类别，假设一共有q类，初始化为原型向量的标记为{t1,t2,……,tq}。从样本中随机选取q个样本点位原型向量{p1, p2 ,……, pq}。初始化一个学习率a,a 取值范围(0,1)。</li>
<li>从样本集中随机选取一个样本(x, y)，计算该样本与q个原型向量的距离（欧几里得距离），找到最小的那个原型向量p，判断样本的标记y与原型向量的标记t是不是一致。若一致则更新为p’ = p + a<em>(x-p)，否则更新为p’ = p – a</em>(x – p)。</li>
<li>重复第2步直到满足停止条件。（如达到最大迭代次数）</li>
<li>返回q个原型向量。</li>
</ol>
<h4 id="高斯混合聚类"><a href="#高斯混合聚类" class="headerlink" title="高斯混合聚类"></a>高斯混合聚类</h4><p>高斯混合聚类：高斯混合聚类与k均值、LVQ用原型向量来刻画聚类结构不同，高斯混合聚类采用概率模型来表达聚类原型。相对于k均值聚类算法使用 k 个原型向量来表达聚类结构，高斯混合聚类使用 k 个高斯概率密度函数混合来表达聚类结构</p>
<p>$$P(x_{i}|y_{k}) = \frac{1}{\sqrt{2\pi\sigma_{y_{k}}^{2}}}exp( -\frac{(x_{i}-\mu_{y_{k}})^2}  {2\sigma_{y_{k}}^{2}}   )$$<br>于是迭代更新 k 个簇原型向量的工作转换为了迭代更新 k 个高斯概率密度函数的任务。每个高斯概率密度函数代表一个簇，当一个新的样本进来时，我们可以通过这 k 的函数的值来为新样本分类</p>
<p>高斯混合模型聚类算法EM步骤如下：</p>
<ol>
<li>猜测有几个类别，既有几个高斯分布。</li>
<li>针对每一个高斯分布，随机给其均值和方差进行赋值。</li>
<li>针对每一个样本，计算其在各个高斯分布下的概率。</li>
<li>针对每一个高斯分布，每一个样本对该高斯分布的贡献可以由其下的概率表示，如概率大则表示贡献大，反之亦然。这样把样本对该高斯分布的贡献作为权重来计算加权的均值和方差。之后替代其原本的均值和方差。</li>
<li>重复3~4直到每一个高斯分布的均值和方差收敛。</li>
</ol>
<p><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/v2-27b00c8cc948bf2ac129cddbfbddb93f_r.jpg" alt="高斯混合模型聚类算法"></p>
<h3 id="层次聚类"><a href="#层次聚类" class="headerlink" title="层次聚类"></a>层次聚类</h3><p>层次聚类(hierarchical clustering)基于簇间的相似度在不同层次上分析数据，从而形成树形的聚类结构，层次聚类一般有两种划分策略：自底向上的聚合（agglomerative）策略和自顶向下的分拆（divisive）策略。</p>
<h4 id="AGNES"><a href="#AGNES" class="headerlink" title="AGNES"></a>AGNES</h4><p>AGNES算法是自底向上的层次聚类算法。开始时将数据集中的每个样本初始化为一个簇，然后找到距离最近的两个簇，将他们合并，不断重复这个过程，直达到到预设的聚类数目为止。</p>
<p>簇间距离的计算可以有三种形式：</p>
<ul>
<li><ul>
<li><strong>最小距离</strong>：$d_{min}(C_i,C_j)=\min_{p\in C_i,q\in C_j}|p-q|.$</li>
</ul>
</li>
<li><ul>
<li><strong>最大距离</strong>：$d_{max}(C_i,C_j)=\max_{p\in C_i,q\in C_j}|p-q|.$</li>
</ul>
</li>
<li><ul>
<li><strong>平均距离</strong>：$d_{avg}(C_i,C_j)=\frac{1}{|C_i||C_j|}\sum_{p\in C_i}\sum_{q\in C_j}|p-q|.$</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>输入</strong>：样本集D={x1,x2,…,xm}D={x1,x2,…,xm}<br>   聚类簇距离度量函数dd；<br>   聚类簇数kk<br><strong>过程</strong>：<br>1： for j=1,2,…,mj=1,2,…,m do<br>2：     Cj={xj}Cj={xj}<br>3： end for<br>4： for i=1,2,…,mi=1,2,…,m do<br>5：  for i=1,2,…,mi=1,2,…,m do<br>6：   M(i,j)=d(Ci,Cj)M(i,j)=d(Ci,Cj);<br>7：   M(j,i)=M(i,j)M(j,i)=M(i,j);<br>8：  end for<br>9： end for<br>10： 设置当前聚类簇个数：q=mq=m;<br>11： while q&gt;kq&gt;k do<br>12：  找出距离最近的两个聚类簇Ci∗Ci∗和Cj∗Cj∗;<br>13：  合并Ci∗Ci∗和Cj∗Cj∗：Ci∗=Ci∗⋃Cj∗Ci∗=Ci∗⋃Cj∗；<br>14：  for j=j∗+1,j∗+2,..,qj=j∗+1,j∗+2,..,q do<br>15：   将聚类簇CjCj重新编号为CjCj<br>16：  end for<br>17：  删除距离矩阵MM的第j∗j∗行和第j∗j∗列;<br>18：  for j=1,2,…,q−1j=1,2,…,q−1 do<br>19：   M(i,j)=d(Ci,Cj)M(i,j)=d(Ci,Cj);<br>20：   M(j,i)=M(i,j)M(j,i)=M(i,j);<br>21：  end for<br>22：  q=q−1q=q−1<br>23： end while<br><strong>输出</strong>：簇划分:C={C1,C2,…,Ck}</p>
</blockquote>
<h4 id="自顶而下"><a href="#自顶而下" class="headerlink" title="自顶而下"></a>自顶而下</h4><p>自顶而下：把整个数据集视作一个簇，然后把一个簇分成几个簇，接着再分别把每一个簇分成更小的簇，如此反复下去，直到满足要求为止。</p>
<h3 id="密度聚类"><a href="#密度聚类" class="headerlink" title="密度聚类"></a>密度聚类</h3><p>密度聚类假设聚类结构通过样本分布的紧密程度。此算法是基于密度的角度来考察样本之间的连接性，并基于连接性不断扩展聚类簇最后获得最终的结果。通过判断样本在区域空间内是否大于某个阈值来决定是否将其放到与之相近的样本中。</p>
<h4 id="DBSCAN-6"><a href="#DBSCAN-6" class="headerlink" title="DBSCAN ^6"></a>DBSCAN <a href="https://blog.csdn.net/zhouxianen1987/article/details/68945844" target="_blank" rel="noopener">^6</a></h4><ul>
<li><strong>e-邻域</strong>:对xj∈D,其∈邻域包含样本集D中与xj的距离不大于e的样本,即N(xj)= {xi∈D | dist(xi,xj)≤e};</li>
<li><strong>核心对象(core object)</strong>: 若xj的E-邻域至少包含MinPts个样本，即|Ne(xj)|≥MinPts,则xj是-一个核心对象;</li>
<li><strong>密度直达(directly density- reachable)</strong>:若xj位于xi的e-邻域中,且xi是核心对象,则称x;由xi密度直达;</li>
<li><strong>密度可达(density. reachable)</strong>: 对xi与xj,若存在样本序列P1,P2,… ,Pn,其中p1=xi,Pn=xj且pi+1由pi密度直达,则称xj由xi密度可达;</li>
<li><strong>密度相连(density-conected)</strong>: 对xi与xj,若存在xk使得xi与xj均由xk密度可达,则称xi与xj密度相连.</li>
</ul>
<blockquote>
<p>首先将数据集D中的所有对象标记为未处理状态<br>1: for（数据集D中每个对象p） do<br>2:     if （p已经归入某个簇或标记为噪声） then<br>3:         continue;<br>4:     else<br>5:         检查对象p的Eps邻域 NEps(p) ；<br>6:         if (NEps(p)包含的对象数小于MinPts) then<br>7:             标记对象p为边界点或噪声点；<br>8:         else<br>9:             标记对象p为核心点，并建立新簇C, 并将p邻域内所有点加入C<br>10:            for (NEps(p)中所有尚未被处理的对象q)  do<br>11:                检查其Eps邻域NEps(q)，若NEps(q)包含至少MinPts个对象，则将NEps(q)中未归入任何一个簇的对象加入C；<br>12:            end for<br>13:        end if<br>14:     end if<br>15: end for</p>
</blockquote>
<h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul>
<li>相比 K-平均算法，DBSCAN 不需要预先声明聚类数量。</li>
<li>DBSCAN 可以找出任何形状的聚类，甚至能找出一个聚类，它包围但不连接另一个聚类，另外，由于 MinPts 参数，single-link effect （不同聚类以一点或极幼的线相连而被当成一个聚类）能有效地被避免。</li>
<li>DBSCAN 能分辨噪音（局外点）。</li>
<li>DBSCAN 只需两个参数，且对数据库内的点的次序几乎不敏感（两个聚类之间边缘的点有机会受次序的影响被分到不同的聚类，另外聚类的次序会受点的次序的影响）。</li>
<li>DBSCAN 被设计成能配合可加速范围访问的数据库结构，例如 R*树。</li>
<li>如果对资料有足够的了解，可以选择适当的参数以获得最佳的分类。</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li>DBSCAN 不是完全决定性的：在两个聚类交界边缘的点会视乎它在数据库的次序决定加入哪个聚类，幸运地，这种情况并不常见，而且对整体的聚类结果影响不大——DBSCAN 对核心点和噪音都是决定性的。DBSCAN* 是一种变化了的算法，把交界点视为噪音，达到完全决定性的结果。</li>
<li>DBSCAN 聚类分析的质素受函数 regionQuery(P,ε) 里所使用的度量影响，最常用的度量是欧几里得距离，尤其在高维度资料中，由于受所谓“维数灾难”影响，很难找出一个合适的 ε ，但事实上所有使用欧几里得距离的算法都受维数灾难影响。</li>
<li>如果数据库里的点有不同的密度，而该差异很大，DBSCAN 将不能提供一个好的聚类结果，因为不能选择一个适用于所有聚类的 minPts-ε 参数组合。</li>
<li>如果没有对资料和比例的足够理解，将很难选择适合的 ε 参数。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="string">'''计算样本点之间的距离</span></span><br><span class="line"><span class="string">    :param data(mat):样本</span></span><br><span class="line"><span class="string">    :return:dis(mat):样本点之间的距离</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    m, n = np.shape(data)</span><br><span class="line">    dis = np.mat(np.zeros((m, m)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i, m):</span><br><span class="line">            <span class="comment"># 计算i和j之间的欧式距离</span></span><br><span class="line">            tmp = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(n):</span><br><span class="line">                tmp += (data[i, k] - data[j, k]) * (data[i, k] - data[j, k])</span><br><span class="line">            dis[i, j] = np.sqrt(tmp)</span><br><span class="line">            dis[j, i] = dis[i, j]</span><br><span class="line">    <span class="keyword">return</span> dis</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_eps</span><span class="params">(distance_D, eps)</span>:</span></span><br><span class="line">    <span class="string">'''找到距离≤eps的样本的索引</span></span><br><span class="line"><span class="string">    :param distance_D(mat):样本i与其他样本之间的距离</span></span><br><span class="line"><span class="string">    :param eps(float):半径的大小</span></span><br><span class="line"><span class="string">    :return: ind(list):与样本i之间的距离≤eps的样本的索引</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    ind = []</span><br><span class="line">    n = np.shape(distance_D)[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> distance_D[<span class="number">0</span>, j] &lt;= eps:</span><br><span class="line">            ind.append(j)</span><br><span class="line">    <span class="keyword">return</span> ind</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dbscan</span><span class="params">(data, eps, MinPts)</span>:</span></span><br><span class="line">    <span class="string">'''DBSCAN算法</span></span><br><span class="line"><span class="string">    :param data(mat):需要聚类的数据集</span></span><br><span class="line"><span class="string">    :param eps(float):半径</span></span><br><span class="line"><span class="string">    :param MinPts(int):半径内最少的数据点数</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">        types(mat):每个样本的类型：核心点、边界点、噪音点</span></span><br><span class="line"><span class="string">        sub_class(mat):每个样本所属的类别</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    m = np.shape(data)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 在types中，1为核心点，0为边界点，-1为噪音点</span></span><br><span class="line">    types = np.mat(np.zeros((<span class="number">1</span>, m)))</span><br><span class="line">    sub_class = np.mat(np.zeros((<span class="number">1</span>, m)))</span><br><span class="line">    <span class="comment"># 用于判断该点是否处理过，0表示未处理过</span></span><br><span class="line">    dealt = np.mat(np.zeros((m, <span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 计算每个数据点之间的距离</span></span><br><span class="line">    dis = distance(data)</span><br><span class="line">    <span class="comment"># 用于标记类别</span></span><br><span class="line">    number = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对每一个点进行处理</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">        <span class="comment"># 找到未处理的点</span></span><br><span class="line">        <span class="keyword">if</span> dealt[i, <span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 找到第i个点到其他所有点的距离</span></span><br><span class="line">            D = dis[i,]</span><br><span class="line">            <span class="comment"># 找到半径eps内的所有点</span></span><br><span class="line">            ind = find_eps(D, eps)</span><br><span class="line">            <span class="comment"># 区分点的类型</span></span><br><span class="line">            <span class="comment"># 边界点</span></span><br><span class="line">            <span class="keyword">if</span> len(ind) &gt; <span class="number">1</span> <span class="keyword">and</span> len(ind) &lt; MinPts + <span class="number">1</span>:</span><br><span class="line">                types[<span class="number">0</span>, i] = <span class="number">0</span></span><br><span class="line">                sub_class[<span class="number">0</span>, i] = <span class="number">0</span></span><br><span class="line">            <span class="comment"># 噪音点</span></span><br><span class="line">            <span class="keyword">if</span> len(ind) == <span class="number">1</span>:</span><br><span class="line">                types[<span class="number">0</span>, i] = <span class="number">-1</span></span><br><span class="line">                sub_class[<span class="number">0</span>, i] = <span class="number">-1</span></span><br><span class="line">                dealt[i, <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">            <span class="comment"># 核心点</span></span><br><span class="line">            <span class="keyword">if</span> len(ind) &gt;= MinPts + <span class="number">1</span>:</span><br><span class="line">                types[<span class="number">0</span>, i] = <span class="number">1</span></span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> ind:</span><br><span class="line">                    sub_class[<span class="number">0</span>, x] = number</span><br><span class="line">                <span class="comment"># 判断核心点是否密度可达</span></span><br><span class="line">                <span class="keyword">while</span> len(ind) &gt; <span class="number">0</span>:</span><br><span class="line">                    dealt[ind[<span class="number">0</span>], <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">                    D = dis[ind[<span class="number">0</span>],]</span><br><span class="line">                    tmp = ind[<span class="number">0</span>]</span><br><span class="line">                    <span class="keyword">del</span> ind[<span class="number">0</span>]</span><br><span class="line">                    ind_1 = find_eps(D, eps)</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> len(ind_1) &gt; <span class="number">1</span>:  <span class="comment"># 处理非噪音点</span></span><br><span class="line">                        <span class="keyword">for</span> x1 <span class="keyword">in</span> ind_1:</span><br><span class="line">                            sub_class[<span class="number">0</span>, x1] = number</span><br><span class="line">                        <span class="keyword">if</span> len(ind_1) &gt;= MinPts + <span class="number">1</span>:</span><br><span class="line">                            types[<span class="number">0</span>, tmp] = <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            types[<span class="number">0</span>, tmp] = <span class="number">0</span></span><br><span class="line">                            </span><br><span class="line">                        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(ind_1)):</span><br><span class="line">                            <span class="keyword">if</span> dealt[ind_1[j], <span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">                                dealt[ind_1[j], <span class="number">0</span>] = <span class="number">1</span></span><br><span class="line">                                ind.append(ind_1[j])</span><br><span class="line">                                sub_class[<span class="number">0</span>, ind_1[j]] = number</span><br><span class="line">                number += <span class="number">1</span></span><br><span class="line">                </span><br><span class="line">    <span class="comment"># 最后处理所有未分类的点为噪音点</span></span><br><span class="line">    ind_2 = ((sub_class == <span class="number">0</span>).nonzero())[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> ind_2:</span><br><span class="line">        sub_class[<span class="number">0</span>, x] = <span class="number">-1</span></span><br><span class="line">        types[<span class="number">0</span>, x] = <span class="number">-1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> types, sub_class</span><br><span class="line">In [ ]:</span><br><span class="line">types, P = dbscan(X, <span class="number">0.1</span>, <span class="number">4</span>)</span><br><span class="line">types, P</span><br></pre></td></tr></table></figure>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><img data-src="https://lingmoumou-blog.oss-cn-beijing.aliyuncs.com/blog/c40f9711/153aceb3cdac953277c6c840339ac023.jpg" alt="聚类方法概述"></p>
<table>
<thead>
<tr>
<th style="text-align:left">Method name（方法名称）</th>
<th style="text-align:left">Parameters（参数）</th>
<th style="text-align:left">Scalability（可扩展性）</th>
<th style="text-align:left">Usecase（使用场景）</th>
<th style="text-align:left">Geometry (metric used)（几何图形（公制使用））</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">K-Means（K-均值）</td>
<td style="text-align:left">number of clusters（聚类形成的簇的个数）</td>
<td style="text-align:left">非常大的 n_samples, 中等的 n_clusters 使用 MiniBatch 代码）</td>
<td style="text-align:left">通用, 均匀的 cluster size（簇大小）, flat geometry（平面几何）, 不是太多的 clusters（簇）</td>
<td style="text-align:left">Distances between points（点之间的距离）</td>
</tr>
<tr>
<td style="text-align:left">Affinity propagation</td>
<td style="text-align:left">damping（阻尼）, sample preference（样本偏好）</td>
<td style="text-align:left">Not scalable with n_samples（n_samples 不可扩展）</td>
<td style="text-align:left">Many clusters, uneven cluster size, non-flat geometry（许多簇，不均匀的簇大小，非平面几何）</td>
<td style="text-align:left">Graph distance (e.g. nearest-neighbor graph)（图距离（例如，最近邻图））</td>
</tr>
<tr>
<td style="text-align:left">Mean-shift</td>
<td style="text-align:left">bandwidth（带宽）</td>
<td style="text-align:left">Not scalable with n_samples （n_samples不可扩展）</td>
<td style="text-align:left">Many clusters, uneven cluster size, non-flat geometry（许多簇，不均匀的簇大小，非平面几何）</td>
<td style="text-align:left">Distances between points（点之间的距离）</td>
</tr>
<tr>
<td style="text-align:left">Spectral clustering</td>
<td style="text-align:left">number of clusters（簇的个数）</td>
<td style="text-align:left">中等的 n_samples, 小的 n_clusters</td>
<td style="text-align:left">Few clusters, even cluster size, non-flat geometry（几个簇，均匀的簇大小，非平面几何）</td>
<td style="text-align:left">Graph distance (e.g. nearest-neighbor graph)（图距离（例如最近邻图））</td>
</tr>
<tr>
<td style="text-align:left">Ward hierarchical clustering</td>
<td style="text-align:left">number of clusters（簇的个数）</td>
<td style="text-align:left">大的 n_samples 和 n_clusters</td>
<td style="text-align:left">Many clusters, possibly connectivity constraints（很多的簇，可能连接限制）</td>
<td style="text-align:left">Distances between points（点之间的距离）</td>
</tr>
<tr>
<td style="text-align:left">Agglomerative clustering</td>
<td style="text-align:left">number of clusters（簇的个数）, linkage type（链接类型）, distance（距离）</td>
<td style="text-align:left">大的 n_samples 和 n_clusters</td>
<td style="text-align:left">Many clusters, possibly connectivity constraints, non Euclidean distances（很多簇，可能连接限制，非欧氏距离）</td>
<td style="text-align:left">Any pairwise distance（任意成对距离）</td>
</tr>
<tr>
<td style="text-align:left">DBSCAN</td>
<td style="text-align:left">neighborhood size（neighborhood 的大小）</td>
<td style="text-align:left">非常大的 n_samples, 中等的 n_clusters</td>
<td style="text-align:left">Non-flat geometry, uneven cluster sizes（非平面几何，不均匀的簇大小）</td>
<td style="text-align:left">Distances between nearest points（最近点之间的距离）</td>
</tr>
<tr>
<td style="text-align:left">Gaussian mixtures（高斯混合）</td>
<td style="text-align:left">many（很多）</td>
<td style="text-align:left">Not scalable（不可扩展）</td>
<td style="text-align:left">Flat geometry, good for density estimation（平面几何，适用于密度估计）</td>
<td style="text-align:left">Mahalanobis distances to centers（ 与中心的马氏距离）</td>
</tr>
<tr>
<td style="text-align:left">Birch</td>
<td style="text-align:left">branching factor（分支因子）, threshold（阈值）, optional global clusterer（可选全局簇）.</td>
<td style="text-align:left">大的 n_clusters 和 n_samples</td>
<td style="text-align:left">Large dataset, outlier removal, data reduction.（大型数据集，异常值去除，数据简化）</td>
<td style="text-align:left">Euclidean distance between points（点之间的欧氏距离）</td>
</tr>
</tbody>
</table>
<ul>
<li>当簇具有特殊的形状，即非平面流体（译注：即该流体的高斯曲率非0），并且标准欧氏距离不是正确的度量标准（metric）时，非平面几何聚类(Non-flat geometry clustering)是非常有用的。这种情况出现在上图的两个顶行中。</li>
<li>用于聚类（clustering）的高斯混合模型（Gaussian mixture models），专用于混合模型描述在 文档的另一章节 。可以将 KMeans 视为具有每个分量的协方差(equal covariance per component)相等的高斯混合模型的特殊情况。</li>
</ul>
<h3 id="sklearn参数详解"><a href="#sklearn参数详解" class="headerlink" title="sklearn参数详解"></a>sklearn参数详解</h3><p><a href="https://sklearn.apachecn.org/docs/0.21.3/22.html" target="_blank" rel="noopener">https://sklearn.apachecn.org/docs/0.21.3/22.html</a></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2>
    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Ling Moumou
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://lingmoumou.github.io/p/2020/01/19/c40f9711/" title="Day5 聚类">https://lingmoumou.github.io/p/2020/01/19/c40f9711/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/datawhale/" rel="tag"># datawhale</a>
              <a href="/tags/ml/" rel="tag"># ml</a>
              <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
              <a href="/tags/machine-learning/" rel="tag"># machine learning</a>
              <a href="/tags/cluster/" rel="tag"># cluster</a>
              <a href="/tags/聚类/" rel="tag"># 聚类</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/p/2020/01/15/5f13e255/" rel="prev" title="Day4 决策树">
      <i class="fa fa-chevron-left"></i> Day4 决策树
    </a></div>
      <div class="post-nav-item">
    <a href="/p/2020/01/19/50902270/" rel="next" title="Day6 朴素贝叶斯">
      Day6 朴素贝叶斯 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#任务"><span class="nav-number">1.</span> <span class="nav-text">任务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#理论部分"><span class="nav-number">1.1.</span> <span class="nav-text">理论部分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#练习部分"><span class="nav-number">1.2.</span> <span class="nav-text">练习部分</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类"><span class="nav-number">2.</span> <span class="nav-text">聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#相关概念"><span class="nav-number">2.1.</span> <span class="nav-text">相关概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#性能度量-4"><span class="nav-number">2.2.</span> <span class="nav-text">性能度量 ^4</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#距离计算"><span class="nav-number">2.3.</span> <span class="nav-text">距离计算</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#欧式距离"><span class="nav-number">2.3.1.</span> <span class="nav-text">欧式距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#曼哈顿距离"><span class="nav-number">2.3.2.</span> <span class="nav-text">曼哈顿距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切比雪夫距离"><span class="nav-number">2.3.3.</span> <span class="nav-text">切比雪夫距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#闵可夫斯基距离"><span class="nav-number">2.3.4.</span> <span class="nav-text">闵可夫斯基距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#余弦距离"><span class="nav-number">2.3.5.</span> <span class="nav-text">余弦距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#马氏距离"><span class="nav-number">2.3.6.</span> <span class="nav-text">马氏距离</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#原型聚类"><span class="nav-number">2.4.</span> <span class="nav-text">原型聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#K均值"><span class="nav-number">2.4.1.</span> <span class="nav-text">K均值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#LVQ-7"><span class="nav-number">2.4.2.</span> <span class="nav-text">LVQ ^7</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高斯混合聚类"><span class="nav-number">2.4.3.</span> <span class="nav-text">高斯混合聚类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#层次聚类"><span class="nav-number">2.5.</span> <span class="nav-text">层次聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#AGNES"><span class="nav-number">2.5.1.</span> <span class="nav-text">AGNES</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#自顶而下"><span class="nav-number">2.5.2.</span> <span class="nav-text">自顶而下</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#密度聚类"><span class="nav-number">2.6.</span> <span class="nav-text">密度聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#DBSCAN-6"><span class="nav-number">2.6.1.</span> <span class="nav-text">DBSCAN ^6</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#优点"><span class="nav-number">2.6.1.1.</span> <span class="nav-text">优点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#缺点"><span class="nav-number">2.6.1.2.</span> <span class="nav-text">缺点</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#优缺点"><span class="nav-number">2.7.</span> <span class="nav-text">优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sklearn参数详解"><span class="nav-number">2.8.</span> <span class="nav-text">sklearn参数详解</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-number">3.</span> <span class="nav-text">参考文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ling Moumou</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">82</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018 – 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ling Moumou</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script data-pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  <script src="/js/local-search.js"></script>












    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = 'true';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

    </div>
</body>
</html>
